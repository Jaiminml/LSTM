{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "scenic-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hourly-nightmare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "formed-methodology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will check the shape of the data frame\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "emerging-bulletin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many values are none and we have to drop it.\n",
    "data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coordinated-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unusual-choir",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ongoing-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have deleted all the data which had NAN values becasue it can affect the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "loaded-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the independent and dependent variables\n",
    "x = df.drop('label',axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "excited-namibia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "israeli-heather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "curious-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "thick-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a vocabulary size \n",
    "vocab_size = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-telling",
   "metadata": {},
   "source": [
    "# One hot representation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "working-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we dropped the values we have to reset the index to make one hot representation of data\n",
    "sentences = x.copy()\n",
    "sentences.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sustainable-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we have to preprocess the text because we have many ounctuations and STOPWORDS in our dataset so we have to preprocess that data\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "indie-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\baps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "owned-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0, len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences['title'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fifteen-browser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hous dem aid even see comey letter jason chaffetz tweet',\n",
       " 'flynn hillari clinton big woman campu breitbart',\n",
       " 'truth might get fire',\n",
       " 'civilian kill singl us airstrik identifi',\n",
       " 'iranian woman jail fiction unpublish stori woman stone death adulteri',\n",
       " 'jacki mason hollywood would love trump bomb north korea lack tran bathroom exclus video breitbart',\n",
       " 'beno hamon win french socialist parti presidenti nomin new york time',\n",
       " 'back channel plan ukrain russia courtesi trump associ new york time',\n",
       " 'obama organ action partner soro link indivis disrupt trump agenda',\n",
       " 'bbc comedi sketch real housew isi caus outrag']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we can see that corpus contains the words after preprocessing done.\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "elect-victim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[799, 4328, 2081, 1189, 2412, 1523, 4734, 2730, 4177, 3343],\n",
       " [789, 3723, 1004, 469, 3679, 640, 3942],\n",
       " [3233, 2945, 4428, 960],\n",
       " [319, 706, 3195, 3286, 4059, 3772],\n",
       " [1370, 3679, 3576, 753, 3943, 2434, 3679, 3568, 4062, 4599],\n",
       " [1552,\n",
       "  4898,\n",
       "  3078,\n",
       "  1018,\n",
       "  3879,\n",
       "  4172,\n",
       "  3357,\n",
       "  111,\n",
       "  3411,\n",
       "  921,\n",
       "  4135,\n",
       "  633,\n",
       "  245,\n",
       "  1333,\n",
       "  3942],\n",
       " [4167, 3143, 2139, 280, 2415, 3467, 3834, 3778, 262, 1889, 3890],\n",
       " [4951, 754, 3187, 2299, 2900, 3170, 4172, 716, 262, 1889, 3890],\n",
       " [2542, 3582, 2114, 138, 1798, 4414, 309, 265, 4172, 4483],\n",
       " [4085, 2039, 3995, 2745, 2436, 4390, 1969, 4511]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that the words in corpus are represented in onehot encode w.r.t. given vocab_size that is 5000\n",
    "onehot = [one_hot(words,vocab_size) for words in corpus]\n",
    "onehot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "constant-supply",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18285"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-uruguay",
   "metadata": {},
   "source": [
    "# Embedding of onehot words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "associate-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df = pd.DataFrame(corpus,columns=['corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "native-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df['length'] = length_df['corpus'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "documentary-excellence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_df['length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "soviet-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we have maximum sentence length is 299 so we will take embedding accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "paperback-antigua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,  799, 4328,\n",
       "        2081, 1189, 2412, 1523, 4734, 2730, 4177, 3343],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,  789, 3723, 1004,  469, 3679,  640, 3942],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 3233, 2945, 4428,  960],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,  319,  706, 3195, 3286, 4059, 3772],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0, 1370, 3679,\n",
       "        3576,  753, 3943, 2434, 3679, 3568, 4062, 4599],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 1552, 4898, 3078, 1018, 3879, 4172, 3357,\n",
       "         111, 3411,  921, 4135,  633,  245, 1333, 3942],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0, 4167, 3143, 2139,\n",
       "         280, 2415, 3467, 3834, 3778,  262, 1889, 3890],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0, 4951,  754, 3187,\n",
       "        2299, 2900, 3170, 4172,  716,  262, 1889, 3890],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0, 2542, 3582,\n",
       "        2114,  138, 1798, 4414,  309,  265, 4172, 4483],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "        4085, 2039, 3995, 2745, 2436, 4390, 1969, 4511]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 30\n",
    "embedding = pad_sequences(onehot,maxlen=length,padding='pre')\n",
    "embedding[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "linear-jonathan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 40)            200000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_features = 40\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,embedding_vector_features,input_length=length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "catholic-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(embedding)\n",
    "Y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "institutional-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "generous-experience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.3419 - accuracy: 0.8393 - val_loss: 0.2180 - val_accuracy: 0.9090\n",
      "Epoch 2/20\n",
      "192/192 [==============================] - 7s 38ms/step - loss: 0.1407 - accuracy: 0.9459 - val_loss: 0.1886 - val_accuracy: 0.9193\n",
      "Epoch 3/20\n",
      "192/192 [==============================] - 8s 42ms/step - loss: 0.0998 - accuracy: 0.9630 - val_loss: 0.2039 - val_accuracy: 0.9138\n",
      "Epoch 4/20\n",
      "192/192 [==============================] - 9s 45ms/step - loss: 0.0746 - accuracy: 0.9743 - val_loss: 0.2494 - val_accuracy: 0.9210\n",
      "Epoch 5/20\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.0501 - accuracy: 0.9833 - val_loss: 0.2686 - val_accuracy: 0.9147\n",
      "Epoch 6/20\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.3054 - val_accuracy: 0.9140\n",
      "Epoch 7/20\n",
      "192/192 [==============================] - 7s 38ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.3647 - val_accuracy: 0.9147\n",
      "Epoch 8/20\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.3490 - val_accuracy: 0.9145\n",
      "Epoch 9/20\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.4349 - val_accuracy: 0.9118\n",
      "Epoch 10/20\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.4878 - val_accuracy: 0.9104\n",
      "Epoch 11/20\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.5491 - val_accuracy: 0.9128\n",
      "Epoch 12/20\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.5711 - val_accuracy: 0.9109\n",
      "Epoch 13/20\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 8.3364e-04 - accuracy: 0.9998 - val_loss: 0.6033 - val_accuracy: 0.9097\n",
      "Epoch 14/20\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.5276 - val_accuracy: 0.9128\n",
      "Epoch 15/20\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 8.2785e-04 - accuracy: 0.9998 - val_loss: 0.6510 - val_accuracy: 0.9123\n",
      "Epoch 16/20\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 2.2597e-04 - accuracy: 1.0000 - val_loss: 0.6830 - val_accuracy: 0.9127\n",
      "Epoch 17/20\n",
      "192/192 [==============================] - 7s 38ms/step - loss: 1.5427e-04 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.9117\n",
      "Epoch 18/20\n",
      "192/192 [==============================] - 8s 41ms/step - loss: 8.5762e-05 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.9125\n",
      "Epoch 19/20\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 6.2109e-05 - accuracy: 1.0000 - val_loss: 0.7485 - val_accuracy: 0.9125\n",
      "Epoch 20/20\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 4.8164e-05 - accuracy: 1.0000 - val_loss: 0.7720 - val_accuracy: 0.9127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e132a1488>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model \n",
    "model.fit(X_train,y_train,batch_size=64,epochs=20,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "large-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "## Creating model\n",
    "embedding_vector_features=40\n",
    "model1=Sequential()\n",
    "model1.add(Embedding(vocab_size,embedding_vector_features,input_length=length))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(LSTM(100))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "compressed-upgrade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200/200 [==============================] - 7s 34ms/step - loss: 0.3364 - accuracy: 0.8423 - val_loss: 0.2181 - val_accuracy: 0.9114\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 7s 33ms/step - loss: 0.1503 - accuracy: 0.9405 - val_loss: 0.1915 - val_accuracy: 0.9183\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.1121 - accuracy: 0.9594 - val_loss: 0.2063 - val_accuracy: 0.9191\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 7s 36ms/step - loss: 0.0873 - accuracy: 0.9674 - val_loss: 0.2205 - val_accuracy: 0.9171\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.0652 - accuracy: 0.9777 - val_loss: 0.2414 - val_accuracy: 0.9116\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 8s 41ms/step - loss: 0.0491 - accuracy: 0.9837 - val_loss: 0.2637 - val_accuracy: 0.9158\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.0371 - accuracy: 0.9879 - val_loss: 0.3301 - val_accuracy: 0.9156\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.3649 - val_accuracy: 0.9121\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 0.3649 - val_accuracy: 0.9094\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 9s 43ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.3576 - val_accuracy: 0.9160\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.4452 - val_accuracy: 0.9110\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.4494 - val_accuracy: 0.9125\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 7s 37ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.4827 - val_accuracy: 0.9103\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.4885 - val_accuracy: 0.9167\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 8s 42ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.5284 - val_accuracy: 0.9121\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 9s 47ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.5020 - val_accuracy: 0.9036\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 0.0082 - accuracy: 0.9967 - val_loss: 0.5348 - val_accuracy: 0.9074\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.5613 - val_accuracy: 0.9109\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6135 - val_accuracy: 0.9103\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 8s 39ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.5597 - val_accuracy: 0.9094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20e0e6360c8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model \n",
    "model1.fit(X_train,y_train,batch_size=64,epochs=20,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-jewelry",
   "metadata": {},
   "source": [
    "We can see that after adding dropout we are not getting accuracy more than 90% so we will take different approaches but we can see the entire process of how LSTM cab ne used in text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-cholesterol",
   "metadata": {},
   "source": [
    "# Now can check the performance of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "united-opening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3132  287]\n",
      " [ 240 2376]]\n",
      "0.9126760563380282\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict_classes(X_test)\n",
    "CM = confusion_matrix(y_test,y_pred)\n",
    "score = accuracy_score(y_test,y_pred)\n",
    "print(CM)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-piano",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
